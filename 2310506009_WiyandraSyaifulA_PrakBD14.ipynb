{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ae225b",
        "outputId": "e4da43da-86fe-4fe4-c5d2-036f052ea427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Inisialisasi SparkSession\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
        "\n",
        "# Contoh dataset\n",
        "data = [(1, [2.0, 3.0], 0), (2, [1.0, 5.0], 1), (3, [2.5, 4.5], 1), (4, [3.0, 6.0], 0)]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Menambahkan kolom baru dengan rata-rata fitur\n",
        "df = df.withColumn('Feature1', df['Features'][0])\n",
        "df = df.withColumn('Feature2', df['Features'][1])\n",
        "\n",
        "# Sekarang kolom 'Features' dibagi menjadi 2, kita perlu menggunakan VectorAssembler untuk menambahkan fitur ke dalam vektor\n",
        "assembler = VectorAssembler(inputCols=['Feature1','Feature2'], outputCol='FeaturesVec')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='FeaturesVec', labelCol='Label')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Menampilkan koefisien dan intercept\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJwa5YP_5ZGn",
        "outputId": "b5cb41a1-11d9-4bf7-cbcf-f2c85c0b76c8"
      },
      "id": "EJwa5YP_5ZGn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inisialisasi SparkSession\n",
        "spark = SparkSession.builder.appName(\"KMeansExample\").getOrCreate()\n",
        "\n",
        "# Contoh dataset\n",
        "data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Menambahkan kolom baru untuk Feature1 dan Feature2 dari Features array\n",
        "df = df.withColumn('Feature1', df['Features'][0])\n",
        "df = df.withColumn('Feature2', df['Features'][1])\n",
        "\n",
        "# Menggunakan VectorAssembler untuk menggabungkan Feature1 dan Feature2 menjadi FeaturesVec\n",
        "assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='FeaturesVec')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='FeaturesVec', k=2, seed=1)  # k=2 untuk 2 cluster\n",
        "model = kmeans.fit(df_transformed)\n",
        "\n",
        "# Menampilkan pusat cluster\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJZArh3F5Ttn",
        "outputId": "331c1a0d-bc82-4ced-90e3-51d5a4e741a0"
      },
      "id": "AJZArh3F5Ttn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([5.33333333, 5.33333333]), array([15., 15.])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inisialisasi SparkSession\n",
        "spark = SparkSession.builder.appName(\"LinearRegressionHomework\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv('Titanic-Dataset-Normal.csv', header=True, inferSchema=True)\n",
        "# Define the feature columns (excluding the target column 'species')\n",
        "feature_columns = ['Age', 'Sex', 'Cabin', 'Embarked', 'Pclass']\n",
        "\n",
        "# Use VectorAssembler to combine feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='Features')\n",
        "df_assembled = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Survived')\n",
        "model = lr.fit(df_assembled)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uN_tX72NMU0",
        "outputId": "76f522a1-913d-4179-f278-ad647c31a2d6"
      },
      "id": "3uN_tX72NMU0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+------+----+---+-------------------+-----+-----+------+--------------------+-----+--------+\n",
            "|         PassengerId|Survived|Pclass|Name|Sex|                Age|SibSp|Parch|Ticket|                Fare|Cabin|Embarked|\n",
            "+--------------------+--------+------+----+---+-------------------+-----+-----+------+--------------------+-----+--------+\n",
            "|                 0.0|     0.0|   1.0| 108|  1| 0.2711736617240512|0.125|  0.0|   523|0.014151057562208049|  147|       2|\n",
            "|0.001123595505617...|     1.0|   0.0| 190|  0| 0.4722292033174164|0.125|  0.0|   596| 0.13913573538264068|   81|       0|\n",
            "|0.002247191011235955|     1.0|   1.0| 353|  0|0.32143754712239253|  0.0|  0.0|   669|0.015468569817999833|  147|       2|\n",
            "|0.003370786516853...|     1.0|   0.0| 272|  0| 0.4345312892686604|0.125|  0.0|    49| 0.10364429745562033|   55|       2|\n",
            "|0.004494382022471...|     0.0|   1.0|  15|  1| 0.4345312892686604|  0.0|  0.0|   472|0.015712553569072387|  147|       2|\n",
            "+--------------------+--------+------+----+---+-------------------+-----+-----+------+--------------------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Coefficients: [-0.39587317290616936,-0.4932474150433713,-0.00040083743929700597,-0.039858417648087514,-0.3353370731951556]\n",
            "Intercept: 1.1820650492396618\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}